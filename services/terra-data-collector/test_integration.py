#!/usr/bin/env python3
"""
Terra Data Collector - í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ê³µê°œ APIì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ëª¨ë“  Exporter íŒŒì´í”„ë¼ì¸ì„ ê²€ì¦í•©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ë²”ìœ„:
  1. Open-Meteo ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
  2. Open-Meteo ê³¼ê±° 30ì¼ ë°ì´í„° ìˆ˜ì§‘ (AI í•™ìŠµìš©)
  3. NASA POWER ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
  4. ThingSpeak ê³µê°œ ì±„ë„ ìˆ˜ì§‘
  5. CSV / JSONL / Parquet ë‚´ë³´ë‚´ê¸° ê²€ì¦
  6. ë‚´ë³´ë‚´ê¸° ë°ì´í„° í’ˆì§ˆ ê²€ì¦

ì„±ê³µ ê¸°ì¤€:
  - ê° Providerì—ì„œ ìµœì†Œ 10ê±´ ì´ìƒ ìˆ˜ì§‘
  - ì „ì²´ ìˆ˜ì§‘ 500ê±´ ì´ìƒ
  - ëª¨ë“  Exporter íŒŒì¼ ì •ìƒ ìƒì„±
  - íŒŒì¸íŠœë‹ JSONLì˜ instruction/input/output í•„ë“œ ìœ íš¨
"""
import asyncio
import json
import sys
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from src.config import load_config
from src.collector import Collector
from src.models import CollectedSensorData


# ============ ìƒ‰ìƒ ìœ í‹¸ ============
class C:
    OK = "\033[92m"
    WARN = "\033[93m"
    FAIL = "\033[91m"
    BOLD = "\033[1m"
    END = "\033[0m"

def ok(msg): print(f"{C.OK}  âœ… {msg}{C.END}")
def warn(msg): print(f"{C.WARN}  âš ï¸ {msg}{C.END}")
def fail(msg): print(f"{C.FAIL}  âŒ {msg}{C.END}")
def header(msg): print(f"\n{C.BOLD}{'='*60}\n  {msg}\n{'='*60}{C.END}")
def section(msg): print(f"\n{C.BOLD}--- {msg} ---{C.END}")


# ============ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶”ì  ============
results = {"pass": 0, "fail": 0, "warnings": 0, "details": []}

def assert_test(name, condition, detail=""):
    if condition:
        ok(f"[PASS] {name}")
        results["pass"] += 1
        results["details"].append(("PASS", name, detail))
    else:
        fail(f"[FAIL] {name} â€” {detail}")
        results["fail"] += 1
        results["details"].append(("FAIL", name, detail))


async def test_realtime_collection(collector: Collector):
    """í…ŒìŠ¤íŠ¸ 1: ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘"""
    header("TEST 1: ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ (Open-Meteo + ThingSpeak)")

    summary = await collector.collect_and_export(
        provider_names=["open_meteo", "thingspeak"],
        exporter_names=["csv_export", "jsonl_export", "parquet_export"],
        historical=False,
    )

    total = summary.total_records
    print(f"  ğŸ“Š ì´ ìˆ˜ì§‘ ë ˆì½”ë“œ: {total}")
    print(f"  ğŸ“¤ ì´ ë‚´ë³´ë‚´ê¸°: {summary.total_exported}")
    print(f"  ğŸ”Œ ì‚¬ìš©ëœ Provider: {summary.providers_used}")

    assert_test(
        "Open-Meteo ì‹¤ì‹œê°„ ìˆ˜ì§‘",
        "open_meteo" in summary.providers_used,
        f"providers: {summary.providers_used}",
    )

    # Open-MeteoëŠ” farm 2ê°œ Ã— ë³€ìˆ˜ 4ê°œ = ìµœì†Œ 8ê±´ ì˜ˆìƒ
    om_result = next((r for r in summary.results if r.provider == "open_meteo"), None)
    if om_result:
        print(f"  ğŸŒ¤ï¸ Open-Meteo: {om_result.records_collected} records, {om_result.duration_ms:.0f}ms")
        assert_test(
            "Open-Meteo ìµœì†Œ ë°ì´í„°ëŸ‰ (â‰¥4ê±´)",
            om_result.records_collected >= 4,
            f"collected: {om_result.records_collected}",
        )
    else:
        fail("Open-Meteo ê²°ê³¼ ì—†ìŒ")
        results["fail"] += 1

    ts_result = next((r for r in summary.results if r.provider == "thingspeak"), None)
    if ts_result:
        print(f"  ğŸ“¡ ThingSpeak: {ts_result.records_collected} records, {ts_result.duration_ms:.0f}ms")
        # ThingSpeak ê³µê°œ ì±„ë„ì€ ê°€ìš©ì„±ì´ ìœ ë™ì ì´ë¯€ë¡œ warningìœ¼ë¡œ ì²˜ë¦¬
        if ts_result.records_collected > 0:
            ok(f"ThingSpeak ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ: {ts_result.records_collected}ê±´")
            results["pass"] += 1
        else:
            warn("ThingSpeak ì±„ë„ ë°ì´í„° ì—†ìŒ (ì±„ë„ ìƒíƒœì— ë”°ë¼ ì •ìƒ)")
            results["warnings"] += 1
    else:
        warn("ThingSpeak ê²°ê³¼ ì—†ìŒ (ê³µê°œ ì±„ë„ ì˜ì¡´)")
        results["warnings"] += 1

    assert_test(
        "ë‚´ë³´ë‚´ê¸° ì„±ê³µ",
        summary.total_exported > 0,
        f"exported: {summary.total_exported}",
    )

    return summary.total_records


async def test_historical_collection(collector: Collector):
    """í…ŒìŠ¤íŠ¸ 2: ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ (AI í•™ìŠµìš© ëŒ€ëŸ‰ ë°ì´í„°)"""
    header("TEST 2: ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ â€” AI í•™ìŠµìš© (Open-Meteo 30ì¼)")

    end = (datetime.now(timezone.utc) - timedelta(days=5)).strftime("%Y-%m-%d")
    start = (datetime.now(timezone.utc) - timedelta(days=35)).strftime("%Y-%m-%d")

    print(f"  ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start} ~ {end} (30ì¼)")

    summary = await collector.collect_and_export(
        provider_names=["open_meteo"],
        exporter_names=["csv_export", "jsonl_export", "parquet_export"],
        historical=True,
        start_date=start,
        end_date=end,
    )

    total = summary.total_records
    print(f"  ğŸ“Š ì´ ìˆ˜ì§‘ ë ˆì½”ë“œ: {total}")
    print(f"  ğŸ“¤ ì´ ë‚´ë³´ë‚´ê¸°: {summary.total_exported}")

    # 30ì¼ Ã— 24ì‹œê°„ Ã— 4ë³€ìˆ˜ Ã— 2ë†ì¥ = ì•½ 5,760ê±´ ì˜ˆìƒ
    assert_test(
        "ê³¼ê±° ë°ì´í„° ëŒ€ëŸ‰ ìˆ˜ì§‘ (â‰¥500ê±´)",
        total >= 500,
        f"collected: {total} (expected â‰¥500 for 30 days)",
    )

    assert_test(
        "ê³¼ê±° ë°ì´í„° ë‚´ë³´ë‚´ê¸°",
        summary.total_exported > 0,
        f"exported: {summary.total_exported}",
    )

    return total


async def test_nasa_power(collector: Collector):
    """í…ŒìŠ¤íŠ¸ 3: NASA POWER ê³¼ê±° ë°ì´í„°"""
    header("TEST 3: NASA POWER ë†ì—… ë°ì´í„° ìˆ˜ì§‘ (ìµœê·¼ 60ì¼)")

    end = (datetime.now(timezone.utc) - timedelta(days=7)).strftime("%Y-%m-%d")
    start = (datetime.now(timezone.utc) - timedelta(days=67)).strftime("%Y-%m-%d")

    print(f"  ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start} ~ {end}")

    summary = await collector.collect_and_export(
        provider_names=["nasa_power"],
        exporter_names=["csv_export", "jsonl_export"],
        historical=True,
        start_date=start,
        end_date=end,
    )

    total = summary.total_records
    print(f"  ğŸ›°ï¸ NASA POWER: {total} records")

    # NASA POWERëŠ” ì¼ ë‹¨ìœ„, 60ì¼ Ã— 6íŒŒë¼ë¯¸í„° Ã— 2ë†ì¥ = ì•½ 720ê±´ ì˜ˆìƒ
    assert_test(
        "NASA POWER ìˆ˜ì§‘ (â‰¥100ê±´)",
        total >= 100,
        f"collected: {total}",
    )

    return total


async def test_exported_files():
    """í…ŒìŠ¤íŠ¸ 4: ë‚´ë³´ë‚´ê¸° íŒŒì¼ ê²€ì¦"""
    header("TEST 4: ë‚´ë³´ë‚´ê¸° íŒŒì¼ í’ˆì§ˆ ê²€ì¦")

    base = Path(__file__).parent / "data" / "exports"

    # CSV ê²€ì¦
    section("CSV Files")
    csv_dir = base / "csv"
    csv_files = list(csv_dir.glob("*.csv"))
    print(f"  ğŸ“ CSV íŒŒì¼ ìˆ˜: {len(csv_files)}")
    assert_test("CSV íŒŒì¼ ìƒì„±ë¨", len(csv_files) > 0, f"count: {len(csv_files)}")

    total_csv_rows = 0
    if csv_files:
        import pandas as pd
        for f in csv_files[:3]:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ í™•ì¸
            df = pd.read_csv(f)
            total_csv_rows += len(df)
            print(f"    ğŸ“„ {f.name}: {len(df)} rows, {list(df.columns)[:6]}...")

        assert_test(
            "CSV ë°ì´í„° í¬í•¨",
            total_csv_rows > 0,
            f"total rows across files: {total_csv_rows}",
        )

        # ì»¬ëŸ¼ í™•ì¸
        sample_df = pd.read_csv(csv_files[0])
        required_cols = {"sensorId", "sensorType", "value", "unit", "farmId", "timestamp"}
        actual_cols = set(sample_df.columns)
        missing = required_cols - actual_cols
        assert_test(
            "CSV í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬",
            len(missing) == 0,
            f"missing: {missing}" if missing else f"all present in {actual_cols}",
        )

    # JSONL ê²€ì¦
    section("JSONL Files (LLM Fine-tuning)")
    jsonl_dir = base / "jsonl"
    jsonl_files = list(jsonl_dir.glob("*.jsonl"))
    print(f"  ğŸ“ JSONL íŒŒì¼ ìˆ˜: {len(jsonl_files)}")
    assert_test("JSONL íŒŒì¼ ìƒì„±ë¨", len(jsonl_files) > 0, f"count: {len(jsonl_files)}")

    if jsonl_files:
        instr_file = jsonl_dir / "finetune_instructions.jsonl"
        if instr_file.exists():
            lines = instr_file.read_text(encoding="utf-8").strip().split("\n")
            print(f"    ğŸ“ finetune_instructions.jsonl: {len(lines)} entries")

            # ì²˜ìŒ 3ê°œ ê²€ì¦
            valid_count = 0
            for line in lines[:5]:
                entry = json.loads(line)
                has_keys = all(k in entry for k in ["instruction", "input", "output"])
                if has_keys and len(entry["output"]) > 10:
                    valid_count += 1

            assert_test(
                "JSONL instruction í˜•ì‹ ìœ íš¨",
                valid_count >= 3,
                f"valid entries: {valid_count}/5",
            )

            # ìƒ˜í”Œ ì¶œë ¥
            sample = json.loads(lines[0])
            print(f"\n    ğŸ“Œ íŒŒì¸íŠœë‹ ìƒ˜í”Œ:")
            print(f"       instruction: {sample['instruction'][:80]}...")
            print(f"       input:       {sample['input']}")
            print(f"       output:      {sample['output'][:100]}...")

        conv_file = jsonl_dir / "finetune_conversations.jsonl"
        if conv_file.exists():
            lines = conv_file.read_text(encoding="utf-8").strip().split("\n")
            print(f"    ğŸ’¬ finetune_conversations.jsonl: {len(lines)} entries")
            assert_test(
                "ShareGPT conversation í˜•ì‹ ìƒì„±",
                len(lines) > 0,
                f"entries: {len(lines)}",
            )

    # Parquet ê²€ì¦
    section("Parquet Files (ML Training)")
    parquet_dir = base / "parquet"
    parquet_files = list(parquet_dir.glob("*.parquet"))
    print(f"  ğŸ“ Parquet íŒŒì¼ ìˆ˜: {len(parquet_files)}")
    assert_test("Parquet íŒŒì¼ ìƒì„±ë¨", len(parquet_files) > 0, f"count: {len(parquet_files)}")

    total_parquet_rows = 0
    if parquet_files:
        import pandas as pd
        for f in parquet_files:
            df = pd.read_parquet(f)
            total_parquet_rows += len(df)
            print(f"    ğŸ—‚ï¸ {f.name}: {len(df)} rows")

        assert_test(
            "Parquet ë°ì´í„° í¬í•¨",
            total_parquet_rows > 0,
            f"total rows: {total_parquet_rows}",
        )

    return total_csv_rows, total_parquet_rows


async def test_data_quality(collector: Collector):
    """í…ŒìŠ¤íŠ¸ 5: ìˆ˜ì§‘ëœ ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
    header("TEST 5: ë°ì´í„° í’ˆì§ˆ ë° í”„ë¡œì íŠ¸ í†µí•© ê²€ì¦")

    # Open-Meteoì—ì„œ ì†ŒëŸ‰ ìˆ˜ì§‘
    records = []
    for name, provider in collector.providers.items():
        if name == "open_meteo":
            records = await provider.collect_all_farms(historical=False)
            break

    if not records:
        warn("ë°ì´í„° ì—†ìŒ, ìŠ¤í‚µ")
        return

    section("ë°ì´í„° í¬ë§· ê²€ì¦")

    # terra-sense í˜ì´ë¡œë“œ í˜¸í™˜ì„±
    for r in records[:3]:
        payload = r.to_terra_sense_payload()
        required = {"sensorId", "sensorType", "value", "unit", "farmId", "timestamp"}
        assert_test(
            f"terra-sense í˜ì´ë¡œë“œ í˜¸í™˜ ({r.sensorType})",
            required.issubset(payload.keys()),
            f"keys: {list(payload.keys())}",
        )
        print(f"    ğŸ“¦ {payload}")

    section("source íƒœê¹… ê²€ì¦ (IoT êµ¬ë¶„)")
    for r in records[:2]:
        assert_test(
            f"source='external' íƒœê¹… ({r.sensorType})",
            r.source == "external",
            f"source: {r.source}",
        )
        assert_test(
            f"provider íƒœê¹… ({r.sensorType})",
            r.provider is not None,
            f"provider: {r.provider}",
        )

    section("ê°’ ë²”ìœ„ ìœ íš¨ì„±")
    for r in records:
        valid_ranges = {
            "temperature": (-50, 60),
            "humidity": (0, 100),
            "soilMoisture": (0, 100),
            "light": (0, 200000),
        }
        rng = valid_ranges.get(r.sensorType)
        if rng:
            in_range = rng[0] <= r.value <= rng[1]
            assert_test(
                f"ê°’ ë²”ìœ„ ìœ íš¨: {r.sensorType}={r.value}{r.unit}",
                in_range,
                f"range: {rng}",
            )

    section("íŒŒì¸íŠœë‹ ë°ì´í„° ìƒì„± ê²€ì¦")
    for r in records[:2]:
        ft = r.to_finetune_instruction()
        print(f"    ğŸ§  {ft['input']} â†’ {ft['output'][:80]}...")
        assert_test(
            f"íŒŒì¸íŠœë‹ output ë ˆì´ë¸” ìƒì„± ({r.sensorType})",
            len(ft["output"]) > 10,
            f"output length: {len(ft['output'])}",
        )


async def main():
    start_time = time.time()

    print(f"""
{C.BOLD}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       ğŸŒ± Terra Data Collector Integration Test           â•‘
â•‘       ì‹¤ì œ ê³µê°œ API ë°ì´í„° ìˆ˜ì§‘ & ë‚´ë³´ë‚´ê¸° í…ŒìŠ¤íŠ¸          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{C.END}
    """)

    # ì„¤ì • ë¡œë“œ & Collector ì´ˆê¸°í™”
    config = load_config()

    # í…ŒìŠ¤íŠ¸ìš©: Kafka ë¹„í™œì„±í™”, íŒŒì¼ Exporterë§Œ í™œì„±í™”
    config.exporters["kafka_bridge"] = {"enabled": False}
    config.exporters["terra_bridge"] = {"enabled": False}

    collector = Collector(config)

    # ê¸°ì¡´ ë‚´ë³´ë‚´ê¸° íŒŒì¼ ì •ë¦¬
    export_base = Path(__file__).parent / "data" / "exports"
    for ext in ["csv", "jsonl", "parquet"]:
        d = export_base / ext
        if d.exists():
            for f in d.glob("*"):
                if f.name != ".gitkeep":
                    f.unlink()

    # ============ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ============
    total_records = 0

    # Test 1: ì‹¤ì‹œê°„
    rt_count = await test_realtime_collection(collector)
    total_records += rt_count

    # Test 2: ê³¼ê±° 30ì¼ (ëŒ€ëŸ‰)
    hist_count = await test_historical_collection(collector)
    total_records += hist_count

    # Test 3: NASA POWER
    nasa_count = await test_nasa_power(collector)
    total_records += nasa_count

    # Test 4: íŒŒì¼ ê²€ì¦
    csv_rows, parquet_rows = await test_exported_files()

    # Test 5: ë°ì´í„° í’ˆì§ˆ
    await test_data_quality(collector)

    # ============ ìµœì¢… ê²°ê³¼ ============
    elapsed = time.time() - start_time

    header("ğŸ“Š FINAL TEST RESULTS")
    print(f"""
  ì´ ìˆ˜ì§‘ ë ˆì½”ë“œ:     {total_records:,}ê±´
  CSV ë‚´ë³´ë‚´ê¸°:       {csv_rows:,}í–‰
  Parquet ë‚´ë³´ë‚´ê¸°:   {parquet_rows:,}í–‰
  ì†Œìš” ì‹œê°„:          {elapsed:.1f}ì´ˆ

  âœ… PASSED:  {results['pass']}
  âŒ FAILED:  {results['fail']}
  âš ï¸ WARNINGS: {results['warnings']}
""")

    if results["fail"] == 0:
        print(f"{C.OK}{C.BOLD}  ğŸ‰ ALL TESTS PASSED! ğŸ‰{C.END}")
    else:
        print(f"{C.FAIL}{C.BOLD}  âš ï¸ {results['fail']} TEST(S) FAILED{C.END}")
        for status, name, detail in results["details"]:
            if status == "FAIL":
                print(f"    {C.FAIL}âœ— {name}: {detail}{C.END}")

    return results["fail"] == 0


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
