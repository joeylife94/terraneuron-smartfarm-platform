"""
CSV Exporter
AI í•™ìŠµìš© CSV ë°ì´í„°ì…‹ ë‚´ë³´ë‚´ê¸°.
pandas DataFrameìœ¼ë¡œ ë³€í™˜ í›„ ì¼ë³„/ì£¼ë³„/ì›”ë³„ ë¶„í•  ì €ì¥.
"""
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

import pandas as pd

from src.models import CollectedSensorData
from src.exporters import BaseExporter

logger = logging.getLogger(__name__)


class CsvExporter(BaseExporter):
    """CSV í˜•ì‹ìœ¼ë¡œ AI í•™ìŠµ ë°ì´í„°ì…‹ ë‚´ë³´ë‚´ê¸°"""

    @property
    def name(self) -> str:
        return "csv_export"

    async def export(self, records: List[CollectedSensorData]) -> int:
        """CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        if not records:
            return 0

        output_dir = Path(self.config.get("output_dir", "./data/exports/csv"))
        output_dir.mkdir(parents=True, exist_ok=True)
        include_metadata = self.config.get("include_metadata", True)

        # DataFrame ë³€í™˜
        if include_metadata:
            rows = [r.to_training_record() for r in records]
        else:
            rows = [r.to_terra_sense_payload() for r in records]

        df = pd.DataFrame(rows)

        # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
        df["_ts"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)

        split_by = self.config.get("split_by", "daily")
        saved = 0

        if split_by == "daily":
            df["_group"] = df["_ts"].dt.strftime("%Y-%m-%d")
        elif split_by == "weekly":
            df["_group"] = df["_ts"].dt.strftime("%Y-W%U")
        elif split_by == "monthly":
            df["_group"] = df["_ts"].dt.strftime("%Y-%m")
        else:
            df["_group"] = "all"

        for group_key, group_df in df.groupby("_group"):
            filename = f"sensor_data_{group_key}.csv"
            filepath = output_dir / filename

            # ë‚´ë¶€ ì¹¼ëŸ¼ ì œê±°
            export_df = group_df.drop(columns=["_ts", "_group"], errors="ignore")

            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ append
            if filepath.exists():
                existing = pd.read_csv(filepath)
                export_df = pd.concat([existing, export_df], ignore_index=True)
                export_df.drop_duplicates(
                    subset=["sensorId", "timestamp"], keep="last", inplace=True,
                )

            export_df.to_csv(filepath, index=False, encoding="utf-8")
            saved += len(group_df)
            logger.debug(f"  ğŸ’¾ {filepath.name}: {len(group_df)} records")

        self._export_count += saved
        logger.info(f"ğŸ’¾ [csv_export] Saved {saved} records to {output_dir}")
        return saved
